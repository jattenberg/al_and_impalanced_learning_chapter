@INPROCEEDINGS{attenberg:hcomp2011,
  author = {Attenberg, Josh and Ipeirotis,Panagiotis and Provost, Foster},
  title = {Beat the Machine: Challenging workers to find the unknown unknowns},
  booktitle = {Proceedings of the 3rd Human Computation Workshop (HCOMP 2011)},
  year = {2011},
  month = {August}
}

@Inproceedings{sindhwani:icml09,
	author = {Vikas Sindhwani and Prem Melville and Richard Lawrence},
	title  ={Uncertainty Sampling and Transductive Experimental Design for Active Dual Supervision},
	year = {2009},
	booktitle = {Proceedings of the 26th International Conference on Machine Learning (ICML-09)}
}
 @inproceedings{liang:icml09,
 author = {Liang, Percy and Jordan, Michael I. and Klein, Dan},
 title = {Learning from measurements in exponential families},
 booktitle = {ICML},
 year = {2009},
 }
@InProceedings{liu:aaai04,
  author = 	 {Bing Liu and Xiaoli Li and Wee Sun Lee and Philip Yu},
  title = 	 {Text classification by labeling words},
  booktitle =	 {AAAI},
  year =	 2004
}
@inproceedings{kunapuli2010:knowledge,
  author = {Kunapuli, Gautam and Bennett, Kristin P. and Shabbeer, Amina and Maclin, Richard and Shavlik, Jude},
  editor = {Balcázar, José L. and Bonchi, Francesco and Gionis, Aristides and Sebag, Michèle},
  booktitle = {ECML/PKDD (2)},

  title = {Online Knowledge-Based Support Vector Machines.},
  url = {http://dblp.uni-trier.de/db/conf/pkdd/pkdd2010-2.html#KunapuliBSMS10},
  volume = 6322,
  year = 2010,
 
}
@inproceedings{druck:sigir08,
  author = 		  {G. Druck and G. Mann and A. McCallum},
  title = 		  {Learning from Labeled Features Using Generalized Expectation Criteria},
  booktitle = {Special Interest Group in Information Retrieval (SIGIR)},
  year = 	  {2008}
}

@inproceedings{melville:naacl09,
 author = {Prem Melville and Vikas Sindhwani},
 title = {Active Dual Supervision: Reducing the Cost of Annotating Examples and Features},
 booktitle = {Proceedings of the NAACL HLT 2009 Workshop on Active Learning for Natural Language Processing},
 year = {2009},
 }
@inproceedings{dayanik:sigir06,
 author = {A. Dayanik and D.  Lewis and D. Madigan and V. Menkov and A. Genkin},
 title = {Constructing informative prior distributions from domain knowledge in text classification},
 booktitle = {SIGIR},
 year = {2006},
  }
@inproceedings{schapire:icml02,
 author = {Robert E. Schapire and Marie Rochery and Mazin G. Rahim and Narendra Gupta},
 title = {Incorporating Prior Knowledge into Boosting},
 booktitle = {International Conference on Machine Learning (ICML)},
 year = {2002},
 }
 @inproceedings{wu:kdd04,
 author = {Xiaoyun Wu and Rohini Srihari},
 title = {Incorporating prior knowledge with weighted margin support vector machines},
 booktitle = {Conference on Knowledge Discovery and Data Mining (KDD)},
 year = {2004},
 }
@INPROCEEDINGS{icdm05:melville,
    AUTHOR      = "Prem Melville and Foster J. Provost and Raymond J. Mooney",
    TITLE       = "An Expected Utility Approach to Active Feature-Value Acquisition",
    BOOKTITLE   = "International Conference on Data Mining",
    PAGES       = "745--748",
    YEAR        = "2005",
}
 @inproceedings{godbole04,
  author = 		  {S. Godbole and A. Harpale and S. Sarawagi and S. Chakrabarti},
  title = 		  {Document Classification through interactive supervision of document and term labels},
  booktitle = {Practice of Knowledge Discovery in Databases (PKDD)},
  year = 	  {2004}
}
@inproceedings{druk:EMNLP:2009,
    author = {Druck, G. and Settles, B. and McCallum, A.},
    booktitle = {Conference on Empirical Methods in Natural Language Processing (EMNLP '09)},
    location = {Singapore},
    pages = {81--90},

    publisher = {Association for Computational Linguistics},
    title = {Active learning by labeling features},
    year = {2009}
}
@Inproceedings{melville:kdd09,
	title =       "Sentiment Analysis of Blogs by Combining Lexical Knowledge with Text Classification",
 	author = {Prem Melville and Wojciech Gryc and Richard Lawrence},
	year = {2009},
	booktitle = {KDD}
}
@inproceedings{attenberg:ecml10,
  author    = {Josh Attenberg and
               Prem Melville and
               Foster J. Provost},
  title     = {A Unified Approach to Active Dual Supervision for Labeling
               Features and Examples},
  booktitle = {European Conference on Machine Learning},
  year      = {2010},
}
@InProceedings{attenberg:GL:blicml:2010,
  author =       "Josh Attenberg and Prem Melville and Foster Provost",
  title =        "Guided Feature Labeling for Budget-Sensitive Learning Under Extreme Class Imbalance",
  booktitle =    {BL-ICML '10: Workshop on Budgeted Learning},
  year =         "2010",
}
@inproceedings{das:1990,
    author = {Croft, Bruce and Das, Raj},
    booktitle = {Proceedings of the ACM SIGIR Conference on Research and Development in Information Retrieval},
    citeulike-article-id = {8322344},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.90.7545},
    pages = {349--368},
    posted-at = {2010-11-29 19:46:20},
    priority = {2},
    title = {{Experiments with query acquisition and use in document retrieval systems}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.90.7545},
    year = {1990}
}
@inproceedings{raghavan:ijcai2005,
    author = {Raghavan, Hema and Madani, Omid and Jones, Rosie},
    booktitle = {Proceedings of the 19th International Joint Conference on Artificial Intelligence},
    location = {Edinburgh, Scotland},
    pages = {841--846},
    title = {{InterActive feature selection}},
    year = {2005}
}
@article{RaghavanJMLR,
    author = {Raghavan, Hema and Madani, Omid and Jones, Rosie and Kaelbling, Leslie},
    citeulike-article-id = {8167479},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.63.662},
    journal = {{Journal of Machine Learning Research}},
    posted-at = {2010-11-01 19:51:34},
    priority = {2},
    title = {{Active learning with feedback on both features and instances}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.63.662},
    volume = {7},
    year = {2006}
}
@inproceedings{Elkan01thefoundations,
    author = {Charles Elkan},
    title = {The Foundations of Cost-Sensitive Learning},
    booktitle = {Proceedings of the Seventeenth International Joint Conference on Artificial Intelligence},
    year = {2001},
    pages = {973--978}
}
@conference{provost2000,
  title={{Machine learning from imbalanced data sets 101}},
  author={Provost, F.},
  booktitle={Proceedings of the AAAI Workshop on Imbalanced Data Sets},
  year={2000}
}
@manual{sasguide,
    address = {Cary, NC},
    organization = {{SAS Institute Inc}},
    author = {{SAS Institute Inc}},
    title = {{Getting Started with SAS Enterprise Miner}},
    year = {2001}
}
@ARTICLE{ml:saar-tsechansky04,
    AUTHOR      = "Maytal Saar-Tsechansky and Foster Provost",
    TITLE       = "Active Sampling for Class Probability Estimation and Ranking",
    YEAR        = 2004,
    JOURNAL     = "Machine Learning",
    VOLUME      = 54,
    NUMBER      = 2,
    PAGES       = "153--178",
}
@phdthesis{lomaskyThesis,
author={Lomasky, Rachel},
title={{Active Acquisition of Informative Training Data}},
school={Tufts University},
year={2010}
}

@inproceedings{lomasky:ecml2007,
    author = {Lomasky, R. and Brodley, C. and Aernecke, M. and Walt, D. and Friedl, M.},
    booktitle = {{Machine Learning: ECML}},
    chapter = {63},
    isbn = {978-3-540-74957-8},
    issn = {0302-9743},
    pages = {640--647},
    title = {{Active Class Selection}},
    volume = {4701},
    year = {2007}
}
@inproceedings{lomasky:nose2006,
  author    = {Lomasky, R. and Brodley, C. E. and Bencic, S. and Aernecke, M. and Walt, D},
  title     = {Guiding class selection for an artificial nose},
  booktitle = {NIPS Workshop on Testing of Deployable Learning and Decision Systems },
  year      = {2006},
}
@inproceedings{Guo:2007optimistic,
 author = {Guo, Yuhong and Greiner, Russ},
 title = {Optimistic active learning using mutual information},
 booktitle = {Proceedings of the 20th international joint conference on Artifical intelligence},
 series = {IJCAI'07},
 year = {2007},
 location = {Hyderabad, India},
 pages = {823--829},
} 
@inproceedings{Moskovitch:2007util,
 author = {Moskovitch, Robert and Nissim, Nir and Stopel, Dima and Feher, Clint and Englert, Roman and Elovici, Yuval},
 title = {Improving the Detection of Unknown Computer Worms Activity Using Active Learning},
 booktitle = {Proceedings of the 30th annual German conference on Advances in Artificial Intelligence},
 series = {KI '07},
 year = {2007},
 isbn = {978-3-540-74564-8},
 location = {Osnabr\&\#252;ck, Germany},
 pages = {489--493},
 numpages = {5},
 url = {http://dx.doi.org/10.1007/978-3-540-74565-5_47},
 doi = {http://dx.doi.org/10.1007/978-3-540-74565-5_47},
 acmid = {1421500},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
 keywords = {Active Learning, Classification, Malcode Detection, Support Vector Machines},
}
@inproceedings{donmez07dual,
    abstract = {Active Learning methods rely on static strategies for sampling unlabeled point(s). These strategies range from uncertainty sampling and density estimation to multi-factor methods with learn-once-use-always model parameters. This paper proposes a dynamic approach, called DUAL, where the strategy selection parameters are adaptively updated based on estimated future residual error reduction after each actively sampled point. The objective of dual is to outperform static strategies over a large operating range: from very few to very many labeled points. Empirical results over six datasets demonstrate that DUAL outperforms several state-of-the-art methods on most datasets.},

    author = {Donmez, Pinar and Carbonell, Jaime G. and Bennett, Paul N.},
    booktitle = {ECML '07},


    title = {Dual Strategy Active Learning},
    url = {http://dx.doi.org/10.1007/978-3-540-74958-5_14},
    year = {2007}
}
@InProceedings{roy:ml01,
  Author         = {Nicholas Roy and Andrew McCallum},
  Title          = {Toward Optimal Active Learning through Sampling
                   Estimation of Error Reduction},
  BookTitle      = {ICML},
  year           = 2001,
}
@inproceedings{dragos05:ijcai,
author = {Dragos D. Margineantu},
title = {Active Cost-Sensitive Learning},
booktitle = {International Joint Conference on Artificial Intelligence},
year = {2005},
masid = {1834614}
}
@article{claudia10xvalid,
 Author         = {Claudia Perlich and Grzegorz Swirszcz},
  Title          = {On Cross-validation and Stacking: Building seemingly predictive models on random data},
  journal   = {SIGKDD Explorations},
  volume    = {12},
  number    = {2},
  year      = {2010},
  pages     = {This issue},
}
@INPROCEEDINGS{Freund94siftinginformative,
    author = {Yoav Freund},
    title = {Sifting Informative Examples From a Random Source.},
    booktitle = {In Working Notes of the Workshop on Relevance, AAAI Fall Symposium Series},
    year = {1994},
    pages = {85--89}
}
@inproceedings{he2007rarecategory,
  author    = {Jingrui He and
               Jaime G. Carbonell},
  title     = {Nearest-Neighbor-Based Active Learning for Rare Category
               Detection},
  booktitle = {NIPS},
  year      = {2007}
}
@article{WeissAIS2020,
    author = {{Weiss, Gary M.}},
    priority = {2},
    title = {{The Impact of Small Disjuncts on Classifier Learning}},
    journal={Annals of Information Systems},
    year={2010},
    volume={8},
    pages={193--226},
}
@INPROCEEDINGS{Schapire90thestrength,
    author = {Robert E. Schapire},
    title = {The Strength of Weak Learnability},
    booktitle = {Machine Learning},
    year = {1990}
}

@article{weiss04miningwrarity,
  author    = {Gary M. Weiss},
  title     = {Mining with rarity: a unifying framework},
  journal   = {SIGKDD Explorations},
  volume    = {6},
  number    = {1},
  year      = {2004},
  pages     = {7-19},
  ee        = {http://doi.acm.org/10.1145/1007730.1007734},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}
@inproceedings{Freund:1993:qbc,
 author = {Freund, Yoav and Seung, H. Sebastian and Shamir, Eli and Tishby, Naftali},
 title = {Information, Prediction, and Query by Committee},
 booktitle = {Advances in Neural Information Processing Systems 5, [NIPS Conference]},
 year = {1993},
 isbn = {1-55860-274-7},
 pages = {483--490},
 numpages = {8},
 url = {http://portal.acm.org/citation.cfm?id=645753.668253},
 acmid = {668253},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
}
@INPROCEEDINGS{Dagan95committeebasedsampling,
    author = {Ido Dagan and Sean P. Engelson},
    title = {Committee-Based Sampling For Training Probabilistic Classifiers},
    booktitle = {In Proceedings of the Twelfth International Conference on Machine Learning},
    year = {1995},
    pages = {150--157},
    publisher = {Morgan Kaufmann}
}
@InProceedings{attenbergAI:blicml:2010,
  author =       "Josh Attenberg and Foster Provost",
  title =        "Active Inference and Learning for Classifying Streams",
  booktitle =    {BL-ICML '10: Workshop on Budgeted Learning},
  year =         "2010",
}
@techreport{rattigan:icdm2007,
    author = {Rattigan, Matthew J. and Maier, Marc and Jensen, David},
	 NUMBER={ 07-22},
    title = {{Exploiting Network Structure for Active Inference in Collective Classification}},
    institution={University of Massachusetts Amherst},
    year = {2007}
}
@article{saar:2007decision,
    abstract = {It can be expensive to acquire the data required for businesses to employ data-driven predictive modeling--for example, to model consumer preferences to optimize targeting. Prior research has introduced "active-learning" policies for identifying data that are particularly useful for model induction, with the goal of decreasing the statistical error for a given acquisition cost (error-centric approaches). However, predictive models are used as part of a decision-making process, and costly improvements in model accuracy do not always result in better decisions. This paper introduces a new approach for active data acquisition that specifically targets decision making. The new decision-centric approach departs from traditional active learning by placing emphasis on acquisitions that are more likely to affect decision making. We describe two different types of decision-centric techniques. Next, using direct-marketing data, we compare various data-acquisition techniques. We demonstrate that strategies for reducing statistical error can be wasteful in a decision-making context, and show that one decision-centric technique in particular can improve targeting decisions significantly. We also show that this method is robust in the face of decreasing quality of utility estimations, eventually converging to uniform random sampling, and that it can be extended to situations where different data acquisitions have different costs. The results suggest that businesses should consider modifying their strategies for acquiring information through normal business transactions. For example, a firm such as Amazon.com that models consumer preferences for customized marketing may accelerate learning by proactively offering recommendations--not merely to induce immediate sales, but for improving recommendations in the future.},
    address = {Institute for Operations Research and the Management Sciences (INFORMS), Linthicum, Maryland, USA},
    author = {Saar-Tsechansky, Maytal and Provost, Foster},
    citeulike-article-id = {6982693},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1528638.1528640},
    citeulike-linkout-1 = {http://dx.doi.org/10.1287/isre.1070.0111},
    citeulike-linkout-2 = {http://isr.journal.informs.org/cgi/content/abstract/18/1/4},
    day = {1},
    doi = {10.1287/isre.1070.0111},
    issn = {1526-5536},
    journal = {INFORMATION SYSTEMS RESEARCH},
    month = mar,
    number = {1},
    pages = {4--22},
    posted-at = {2011-02-19 03:43:03},
    priority = {2},
    publisher = {INFORMS},
    title = {{Decision-Centric} Active Learning of {Binary-Outcome} Models},
    url = {http://dx.doi.org/10.1287/isre.1070.0111},
    volume = {18},
    year = {2007}
}

@inproceedings{donmez:labelaccy2009,
    address = {New York, NY, USA},
    author = {Donmez, Pinar and Carbonell, Jaime G. and Schneider, Jeff},
    booktitle = {Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining},
    citeulike-article-id = {6198490},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1557053},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1557019.1557053},

    doi = {10.1145/1557019.1557053},
    isbn = {978-1-60558-495-9},
    keywords = {active\_learning, labeler\_accuracy},
    location = {Paris, France},
    pages = {259--268},
    posted-at = {2010-08-19 19:47:07},
    priority = {0},
    publisher = {ACM},
    series = {KDD '09},
    title = {Efficiently learning the accuracy of labeling sources for selective sampling},
    url = {http://dx.doi.org/10.1145/1557019.1557053},
    year = {2009}
}
@inproceedings{settles:2008sequence,
    abstract = {{Active learning is well-suited to many problems in natural language processing, where unlabeled data may be abundant but annotation is slow and expensive. This paper aims to shed light on the best active learning approaches for sequence labeling tasks such as information extraction and document segmentation. We survey previously used query selection strategies for sequence models, and propose several novel algorithms to address their shortcomings. We also conduct a large-scale empirical comparison using multiple corpora, which demonstrates that our proposed methods advance the state of the art.}},
    address = {Stroudsburg, PA, USA},
    author = {Settles, Burr and Craven, Mark},
    booktitle = {Proceedings of the Conference on Empirical Methods in Natural Language Processing},
    citeulike-article-id = {8825008},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1613855},
    keywords = {active\_learning, density\_sensitive},
    location = {Honolulu, Hawaii},
    pages = {1070--1079},
    posted-at = {2011-02-15 22:46:30},
    priority = {2},
    publisher = {Association for Computational Linguistics},
    series = {EMNLP '08},
    title = {{An analysis of active learning strategies for sequence labeling tasks}},
    url = {http://portal.acm.org/citation.cfm?id=1613855},
    year = {2008}
}
@inproceedings{davison:2000locality,
    abstract = {Most web pages are linked to others with related content. This idea, combined with another that says that text in, and possibly around, {HTML} anchors describe the pages to which they point, is the foundation for a usable {World-Wide} Web. In this paper, we examine to what extent these ideas hold by empirically testing whether topical locality mirrors spatial locality of pages on the Web. In particular, we find that the likelihood of linked pages having similar textual content to be high; the similarity of sibling pages increases when the links from the parent are close together; titles, descriptions, and anchor text represent at least part of the target page; and that anchor text may be a useful discriminator among unseen child pages. These results show the foundations necessary for the success of many web systems, including search engines, focused crawlers, linkage analyzers, and intelligent web agents.},
    address = {New York, NY, USA},
    author = {Davison, Brian D.},
    booktitle = {Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval},
    citeulike-article-id = {2410443},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=345508.345597},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/345508.345597},
    doi = {10.1145/345508.345597},
    isbn = {1-58113-226-3},
    location = {Athens, Greece},
    pages = {272--279},
    posted-at = {2011-02-18 17:41:52},
    priority = {2},
    publisher = {ACM},
    series = {SIGIR '00},
    title = {Topical locality in the Web},
    url = {http://dx.doi.org/10.1145/345508.345597},
    year = {2000}
}
@inproceedings{elkan:2001cost,
    abstract = {{This paper revisits the problem of optimal learning and decision-making when different misclassification errors incur different penalties. We characterize precisely but intuitively when a cost matrix is reasonable, and we show how to avoid the mistake of defining a cost matrix that is economically incoherent. For the two-class case, we prove a theorem that shows how to change the proportion of negative examples in a training set in order to make optimal cost-sensitive classification decisions...}},
    author = {Elkan, Charles},
    booktitle = {IJCAI},
    citeulike-article-id = {2266473},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.29.514},
    keywords = {cost-sensitive, decision-making, imbalanced, ml, optimal, rebalancing},
    pages = {973--978},
    posted-at = {2008-01-21 08:52:01},
    priority = {0},
    title = {{The Foundations of Cost-Sensitive Learning}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.29.514},
    year = {2001}
}
@inproceedings{Beygelzimer:2009,
 author = {Beygelzimer, Alina and Dasgupta, Sanjoy and Langford, John},
 title = {Importance weighted active learning},
 booktitle = {Proc of the 26th Intl Conf on Machine Learning},
 series = {ICML '09},
 year = {2009},
}
@article{attenberg:2010inactive,
 Author         = {Josh Attenberg and Foster Provost},
  Title          = {{Inactive Learning? Difficulties Employing Active Learning in Practice}},
  journal   = {SIGKDD Explorations},
  volume    = {12},
  number    = {2},
  year      = {2010},
  pages     = {36--41},
}
@inproceedings{nguyen2004preclustering,
    author = {Nguyen, Hieu T. and Smeulders, Arnold},
    booktitle = {ICML},
    title = {Active learning using pre-clustering},
    year = {2004}
}
@inproceedings{he:2010musera,
    abstract = {{Learning from data streams has inspired considerable interests in recent years due to its wide applications in the fields such as network intrusion detection, credit fraud identification, spam filtering, and many others. Given the fact that most algorithms developed thus far assume the class distribution of the streaming data is relatively balanced, they will inevitably be confronted with severe performance deterioration when handling the imbalanced data streams. Evolved from our previous work SERA (SElectively Recursive Approach), the MuSeRA algorithm is proposed in this paper to deal with the problem of learning from imbalanced data streams. By maintaining an ensemble consisting of hypotheses built upon the coming training data chunks balanced by selectively accommodating previous minority examples, MuSeRA can efficiently learn the target concept of the imbalanced data streams and thus obtain substantial performance improvement compared to our previous work SERA and the existing stream data mining algorithms. Simulation results validate the effectiveness of the proposed MuSeRA algorithm.}},
    author = {Chen, Sheng and He, Haibo and Li, Kang and Desai, Sachi},
    citeulike-article-id = {8813906},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/IJCNN.2010.5596538},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5596538},
    doi = {10.1109/IJCNN.2010.5596538},
    location = {Barcelona, Spain},
    month = {July},
    pages = {1--8},
    posted-at = {2011-02-13 02:06:33},
    priority = {2},
    booktitle={Prof. Int. Joint Conf. Neural Networks (IJCNN'10},
    title = {{MuSeRA: Multiple Selectively Recursive Approach towards imbalanced stream data mining}},
    url = {http://dx.doi.org/10.1109/IJCNN.2010.5596538},
    year = {2010}
}
@inproceedings{cmccallum98em,
    abstract = {This paper shows how a text classifier's need for labeled training documents can be reduced by taking advantage of a large pool of unlabeled documents. We modify the Query-by-Committee (QBC) method of active learning to use the unlabeled pool for explicitly estimating document density when selecting examples for labeling. Then active learning is combined with Expectation-Maximization in order to  ” fill in ” the class labels of those documents that remain unlabeled. Experimental results show that the improvements to active learning require less than two-thirds as many labeled training examples as previous QBC approaches, and that the combination of EM and active learning requires only slightly more than half as many labeled training examples to achieve the same accuracy as either the improved active learning or EM alone. 1},
    author = {Mccallum, Andrew K. and Nigam, Kamal},
    booktitle = {ICML},
    citeulike-article-id = {7937547},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.85.7388},
    posted-at = {2010-10-01 21:51:50},
    priority = {2},
    title = {Employing EM in pool-based active learning for text classification},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.85.7388},
    year = {1998}
}
@article{church:1991,
    abstract = {{In principle, n-gram probabilities can be estimated from a large sample of text by counting the number of occurrences of each n-gram of interest and dividing by the size of the training sample. This method, which is known as maximum likelihood estimator (MLE), is very simple. However, it is unsuitable because n-grams which do not occur in the training sample are assigned zero probability. This is qualitatively wrong for use as a prior model, because it would never allow the n-gram, while clearly some of the unseen n-grams will occur in other texts. For non-zero frequencies, the MLE is quantitatively wrong. Moreover, at all frequencies, the MLE does not separate bigrams with the same frequency. We study two alternative methods. The first method is an enhanced version of the method due to Good and Turing (I. J. Good [1953]. Biometrika, 40, 237–264). Under the modest assumption that the distribution of each bigram is binomial, Good provided a theoretical result that increases estimation accuracy. The second method is an enhanced version of the deleted estimation method (F. Jelinek \& R. Mercer [1985]. IBM Technical Disclosure Bulletin, 28, 2591–2594). It assumes even less, merely that the training and test corpora are generated by the same process. We emphasize three points about these methods. First, by using a second predictor of the probability in addition to the observed frequency, it is possible to estimate different probabilities for bigrams with the same frequency. We refer to this use of a second predictor as  ” enhancement.” With enhancement, we find 1200 significantly different probabilities (with a range of five orders of magnitude) for the group of bigrams not observed in the training text; the MLE method would not be able to distinguish any one of these bigrams from any other. The probabilities found by the enhanced methods agree quite closely in qualitative comparisons with the standard calculated from the test corpus. Second, the enhanced Good-Turing method provides accurate predictions of the variances of the standard probabilities estimated from the test corpus. Third, we introduce a refined testing method that enables us to measure the prediction errors directly and accurately and thus to study small differences between methods. We find that while the errors of both methods are small due to the large amount of data that we use, the enhanced Good-Turing method is three to four times as efficient in its use of data as the enhanced deleted estimate method. Good-Turing method is preferable to the enhanced deleted estimate method. Both methods are much better than MLE.}},
    author = {Church, K. and Gale, W.},
    citeulike-article-id = {8219891},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/0885-2308(91)90016-J},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/0885-2308(91)90016-J},
    doi = {10.1016/0885-2308(91)90016-J},
    issn = {08852308},
    journal = {Computer Speech \& Language},
    month = {January},
    number = {1},
    pages = {19--54},
    posted-at = {2010-11-08 23:51:06},
    priority = {2},
    title = {{A comparison of the enhanced Good-Turing and deleted estimation methods for estimating probabilities of English bigrams}},
    url = {http://dx.doi.org/10.1016/0885-2308(91)90016-J},
    volume = {5},
    year = {1991}
}
@book{manning:nlpbook,
    abstract = {{"Statistical natural-language processing is, in my estimation, one of the most
fast-moving and exciting areas of computer science these days. Anyone who
wants to learn this field would be well advised to get this book. For that
matter, the same goes for anyone who is already in the field. I know that it
is going to be one of the most well-thumbed books on my bookshelf." -- Eugene
Charniak, Department of Computer Science, Brown University

Statistical approaches to processing natural language text have become
dominant in recent years. This foundational text is the first comprehensive
introduction to statistical natural language processing (NLP) to appear. The
book contains all the theory and algorithms needed for building NLP tools. It
provides broad but rigorous coverage of mathematical and linguistic
foundations, as well as detailed discussion of statistical methods, allowing
students and researchers to construct their own implementations. The book
covers collocation finding, word sense disambiguation, probabilistic parsing,
information retrieval, and other applications.

More on this book}},
    author = {Manning, Christopher D. and Schuetze, Hinrich},
    citeulike-article-id = {105906},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20&amp;path=ASIN/0262133601},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21&amp;path=ASIN/0262133601},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21&amp;path=ASIN/0262133601},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0262133601},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0262133601/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/0262133601},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0262133601},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0262133601},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0262133601&index=books&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0262133601},
    day = {18},
    edition = {1},
    howpublished = {Hardcover},
    isbn = {0262133601},
    month = {June},
    posted-at = {2011-02-14 19:18:52},
    priority = {2},
    publisher = {The MIT Press},
    title = {{Foundations of Statistical Natural Language Processing}},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/0262133601},
    year = {1999}
}
@inproceedings{xu03representitive,
    abstract = {Abstract. In order to reduce human efforts, there has been increasing interest in applying active learning for training text classifiers. This paper describes a straightforward active learning heuristic, representative sampling, which explores the clustering structure of 'uncertain ' documents and identifies the representative samples to query the user opinions, for the purpose of speeding up the convergence of Support Vector Machine (SVM) classifiers. Compared with other active learning algorithms, the proposed representative sampling explicitly addresses the problem of selecting more than one unlabeled documents. In an empirical study we compared representative sampling both with random sampling and with SVM active learning. The results demonstrated that representative sampling offers excellent learning performance with fewer labeled documents and thus can reduce human efforts in text classification tasks. 1},
    author = {Xu, Zhao and Yu, Kai and Tresp, Volker and Xu, Xiaowei and Wang, Jizhi},
    citeulike-article-id = {7937558},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.153.5892},
    posted-at = {2010-10-01 21:54:43},
    priority = {2},
    title = {Representative sampling for text classification using support vector machines},booktitle={{ECIR}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.153.5892},
    year = {2003}
}
@article{herbei:2005,
    abstract = {{The authors study binary classification that allows for a reject option in which case no decision is made. This reject option is to be used for those observations for which the conditional class probabilities are close and as such are hard to classify. The authors generalize existing theory for both plug-in rules and empirical risk minimizers to this setting. La classification \`{a} clause de renvoi Les auteurs s'int\'{e}ressent \`{a} une m\'{e}thode de classification dichotomique permettant de laisser en suspens le classement de certaines observations dont les probabilit\'{e}s conditionnelles d'appartenance \`{a} l'une ou l'autre classe sont si proches qu'un choix est difficile \`{a} faire. Les auteurs \'{e}tudient dans ce contexte les propri\'{e}t\'{e}s des r\`{e}gles de substitution et des r\`{e}gles de classement minimisant le risque empirique.}},
    author = {Herbei, Radu and Wegkamp, Marten H.},
    citeulike-article-id = {8813315},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/cjs.5550340410},
    doi = {10.1002/cjs.5550340410},
    journal = {Can J Statistics},
    number = {4},
    pages = {709--721},
    posted-at = {2011-02-12 16:43:56},
    priority = {2},
    publisher = {Wiley-Blackwell},
    title = {{Classification with reject option}},
    url = {http://dx.doi.org/10.1002/cjs.5550340410},
    volume = {34},
    year = {2006}
}
@article{chow:70,
    abstract = {{The performance of a pattern recognition system is characterized by its error and reject tradeoff. This paper describes an optimum rejection rule and presents a general relation between the error and reject probabilities and some simple properties of the tradeoff in the optimum recognition system. The error rate can be directly evaluated from the reject function. Some practical implications of the results are discussed. Examples in normal distributions and uniform distributions are given.}},
    author = {Chow, C.},
    booktitle = {Information Theory, IEEE Transactions on},
    journal = {IEEE Transactions on Information Theory},
    month = {January},
    number = {1},
    pages = {41--46},
    title = {{On optimum recognition error and reject tradeoff}},

    volume = {16},
    year = {1970}
}
@article{chow:57,
    abstract = {{The character recognition problem, usually resulting from characters being corrupted by printing deterioration and/or inherent noise of the devices, is considered from the viewpoint of statistical decision theory. The optimization consists of minimizing the expected risk for a weight function which is preassigned to measure the consequences of system decisions As an alternative minimization of the error rate for a given rejection rate is used as the critenon. The optimum recogition is thus obtained. The optimum system consists of a conditional-probability densisities computer; character channels, one for each character; a rejection channel; and a comparison network. Its precise structure and and ultimate performance depend essentially upon the signals and noise structure. Explicit examples for an additive Gaussian noise and a ``cosine'' noise are presented. Finally, an error-free recognition system and a possible criterion to measure the character style and deteriortation are presented.}},
    author = {Chow, C. K.},
    journal = {IEEE Transactions on Electronic Computers},
    month = {December},
    number = {4},
    pages = {247--254},
    title = {{An Optimum Character Recognition System Using Decision Functions}},
    year = {1957}
}
@article{spink:aolqueries,
    author = {Spink, Amanda and Wolfram, Dietmar and Jansen, Major B. J. and Saracevic, Tefko},
    journal = {J. Am. Soc. Inf. Sci. Technol.},
    month = {February},
    pages = {226--234},
    title = {{Searching the Web: the public and their queries}},
    volume = {52},
    year = {2001}
}


@inproceedings{giura:2010raid,
 author = {Giura, Paul and Memon, Nasir},
 title = {NetStore: an efficient storage infrastructure for network forensics and monitoring},
 booktitle = {Proceedings of the 13th international conference on Recent advances in intrusion detection},
 series = {RAID'10},
 year = {2010},
 isbn = {3-642-15511-1, 978-3-642-15511-6},
 location = {Ottawa, Ontario, Canada},
 pages = {277--296},
 numpages = {20},
 url = {http://portal.acm.org/citation.cfm?id=1894166.1894186},
 acmid = {1894186},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
}


@article{good1956bio,

    author = {Good, I. J. and Toulmin, G. H.},
    citeulike-article-id = {8481520},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/biomet/43.1-2.45},
    citeulike-linkout-1 = {http://biomet.oxfordjournals.org/content/43/1-2/45.abstract},
    citeulike-linkout-2 = {http://biomet.oxfordjournals.org/content/43/1-2/45.full.pdf},
    day = {1},
    doi = {10.1093/biomet/43.1-2.45},
    journal = {Biometrika},
    month = {June},
    number = {1-2},
    pages = {45--63},
    posted-at = {2010-12-23 17:18:14},
    priority = {2},
    title = {THE NUMBER OF NEW SPECIES, AND THE INCREASE IN POPULATION COVERAGE, WHEN A SAMPLE IS INCREASED},
    url = {http://dx.doi.org/10.1093/biomet/43.1-2.45},
    volume = {43},
    year = {1956}
}
@article{gale:95tears,
    author = {Gale, William A.},
    citeulike-article-id = {8178933},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.110.8518},
    journal = {Journal of Quantitative Linguistics},
    keywords = {frequency\_estimation, good-turing},
    posted-at = {2010-11-02 16:06:00},
    priority = {2},
    title = {{Good-Turing smoothing without tears}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.110.8518},
    volume = {2},
    year = {1995}
}

@inproceedings{yuanreject,
  author    = {Ming Yuan and
               Marten H. Wegkamp},
  title     = {Classification Methods with Reject Option Based on Convex
               Risk Minimization},
  booktitle   = {Journal of Machine Learning Research},
  volume    = {11},
  year      = {2010},
  pages     = {111-130},
}
@inproceedings{domingosrichardsonKDD2001,
  author    = {Pedro Domingos and
               Matthew Richardson},
  title     = {Mining the network value of customers},
  booktitle = {KDD},
  year      = {2001},

}
@article{AralPNAS09,
    author = {Aral, Sinan and Muchnik, Lev and Sundararajan, Arun},

    journal = {Proceedings of the National Academy of Sciences},
       month = {December},
    number = {51},
    pages = {21544--21549},
   title = {Distinguishing influence-based contagion from homophily-driven diffusion in dynamic networks},
    volume = {106},
    year = {2009}
}
@INPROCEEDINGS{Fumera03f:classification,
    author = {Giorgio Fumera and Ignazio Pillai and Fabio Roli},
    title = {Classification with Reject Option in Text Categorisation Systems},
    booktitle = {In: Proc. 12th International Conference on Image Analysis and Processing. IEEE Computer Society},
    year = {2003},
    pages = {582--587}
}
@article{bartletthinge,
  author    = {Peter L. Bartlett and
               Marten H. Wegkamp},
  title     = {Classification with a Reject Option using a Hinge Loss},
  journal   = {Journal of Machine Learning Research},
  volume    = {9},
  year      = {2008},
  pages     = {1823-1840},
}
@INPROCEEDINGS{Platt99probabilisticoutputs,
    author = {John C. Platt},
    title = {Probabilistic Outputs for Support Vector Machines and Comparisons to Regularized Likelihood Methods},
    booktitle = {ADVANCES IN LARGE MARGIN CLASSIFIERS},
    year = {1999},
    pages = {61--74},
    publisher = {MIT Press}
}
@INPROCEEDINGS{Niculescu-mizil05predictinggood,
    author = {Alexandru Niculescu-mizil and Rich Caruana},
    title = {Predicting Good Probabilities with Supervised Learning},
    booktitle = {In Proc. Int. Conf. on Machine Learning (ICML},
    year = {2005},
    pages = {625--632}
}
@article{Lin:2007:noteOnPlatt,
 author = {Lin, Hsuan-Tien and Lin, Chih-Jen and Weng, Ruby C.},
 title = {A note on Platt's probabilistic outputs for support vector machines},
 journal = {Mach. Learn.},
 volume = {68},
 issue = {3},
 month = {October},
 year = {2007},
 issn = {0885-6125},
 pages = {267--276},
 numpages = {10},
 url = {http://portal.acm.org/citation.cfm?id=1286062.1286078},
 doi = {10.1007/s10994-007-5018-6},
 acmid = {1286078},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 keywords = {Posterior probability, Support vector machine},
}

@INPROCEEDINGS{bennett:online,
AUTHOR = "Paul N. Bennett and Vitor R. Carvalho",
TITLE = "Online stratified sampling: evaluating classifiers at web-scale.",
booktitle = "CIKM'10",

YEAR = {2010}  }

		
@inproceedings{activerisk2010,
    abstract = {{We address the problem of evaluating the risk of a given model accurately at minimal labeling costs. This problem occurs in situations in which risk estimates cannot be obtained from held-out training data, because the training data are unavailable or do not reflect the desired test distribution. We study active risk estimation processes in which instances are actively selected by a sampling process from a pool of unlabeled test instances and their labels are queried. We derive the sampling distribution that minimizes the estimation error of the active risk estimator when used to select instances from the pool. An analysis of the distribution that governs the estimator leads to confidence intervals. We empirically study conditions under which the active risk estimate is more accurate than a standard risk estimate that draws equally many instances from the test distribution. 1.}},
    author = {{Sawade, Christoph} and {Bickel, Steffen} and {Scheffer, Tobias}},
    citeulike-article-id = {8147558},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.170.2447},
    posted-at = {2010-10-29 17:12:54},
    priority = {2},
    title = {{Active Risk Estimation}},
    booktitle={ICML},
    year={2010},
}

@inproceedings{helmboldlabel,
 author = {Helmbold, David and Panizza, Sandra},
 title = {Some label efficient learning results},
 booktitle = {COLT '97: Proceedings of the tenth annual conference on Computational learning theory},
 year = {1997},

 publisher = {ACM},
 }
@article{bianchilabelefficient,
    abstract = {Abstract. We investigate label efficient prediction, a variant of the problem of prediction with expert advice, proposed by Helmbold and Panizza, in which the forecaster does not have access to the outcomes of the sequence to be predicted unless he asks for it, which he can do for a limited number of times. We determine matching upper and lower bounds for the best possible excess error when the number of allowed queries is a constant. We also prove that a query rate of order (ln n)(ln ln n) 2 /n is sufficient for achieving Hannan consistency, a fundamental property in game-theoretic prediction models. Finally, we apply the label efficient framework to pattern classification and prove a label efficient mistake bound for a randomized variant of Littlestone's zero-threshold Winnow algorithm. 1},
    author = {Cesa-bianchi, Nicol\`{o} and Lugosi, G\'{a}bor and Stoltz, Gilles},
    journal = {IEEE Trans. Inform. Theory},
    pages = {77--92},
    title = {Minimizing regret with label efficient prediction},
      volume = {51},
    year = {2005}
}
@ inproceedings{bianchiselective,
    abstract = {A selective sampling algorithm is a learning algorithm for classification that, based on the past observed data, decides whether to ask the label of each new instance to be classified. In this paper, we introduce a general technique for turning linear-threshold classification algorithms from the general additive family into randomized selective sampling algorithms. For the most popular algorithms in this family we derive mistake bounds that hold for individual sequences of examples. These bounds show that our semi-supervised algorithms can achieve, on average, the same accuracy as that of their fully supervised counterparts, but using fewer labels. Our theoretical results are corroborated by a number of experiments on real-world textual data. The outcome of these experiments is essentially predicted by our theoretical results: Our selective sampling algorithms tend to perform as well as the algorithms receiving the true label after each classification, while observing in practice substantially fewer labels.},
    author = {Bianchi, Nicol\`{o} C. and Gentile, Claudio and Zaniboni, Luca},
    booktitle = {J. Mach. Learn. Res.},
    pages = {1205--1230},
    priority = {2},
    title = {Worst-Case Analysis of Selective Sampling for Linear Classification},
    volume = {7},
    year = {2006},
}

@inproceedings{nguyen:clustering,

    author = {Nguyen, Hieu T. and Smeulders, Arnold},
    booktitle = {ICML '04: Proceedings of the twenty-first international conference on Machine learning},
    title = {Active learning using pre-clustering},
    year = {2004}
}

@inproceedings{sculley:onlinespam,

    author = {Sculley, D.},
    booktitle = {Fourth Conf. on Email and AntiSpam},
    title = {Online Active Learning Methods for Fast Label-Efficient Spam Filtering},
    year = {2007}
}

@inproceedings{richardson:2002viral,
    abstract = {Viral marketing takes advantage of networks of influence among customers to inexpensively achieve large changes in behavior. Our research seeks to put it on a firmer footing by mining these networks from data, building probabilistic models of them, and using these models to choose the best viral marketing plan. Knowledge-sharing sites, where customers review products and advise each other, are a fertile source for this type of data mining. In this paper we extend our previous techniques, achieving a large reduction in computational cost, and apply them to data from a knowledge-sharing site. We optimize the amount of marketing funds spent on each customer, rather than just making a binary decision on whether to market to him. We take into account the fact that knowledge of the network is partial, and that gathering that knowledge can itself have a cost. Our results show the robustness and utility of our approach.},
    address = {New York, NY, USA},
    author = {Richardson, Matthew and Domingos, Pedro},
    booktitle = {Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining},
    citeulike-article-id = {972361},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=775047.775057},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/775047.775057},
    doi = {10.1145/775047.775057},
    isbn = {1-58113-567-X},
    location = {Edmonton, Alberta, Canada},
    pages = {61--70},
    posted-at = {2011-02-18 18:10:24},
    priority = {2},
    publisher = {ACM},
    series = {KDD '02},
    title = {Mining knowledge-sharing sites for viral marketing},
    url = {http://dx.doi.org/10.1145/775047.775057},
    year = {2002}
}
@techreport{rattigan:2007network,
    author = {Rattigan, Matthew J. and Maier, Marc and Jensen, David},
	 NUMBER={ 07-22},
    title = {{Exploiting Network Structure for Active Inference in Collective Classification}},
    institution={University of Massachusetts Amherst},
    year = {2007}
}
@inproceedings{bilgic:aaai2010,
    abstract = {{Labeling nodes in a network is an important problem that has seen a growing interest. A number of methods that exploit both local and relational information have been developed for this task. Acquiring the labels for a few nodes at inference time can greatly improve the accuracy, however the question of figuring out which node labels to acquire is challenging. Previous approaches have been based on simple structural properties. Here, we present a novel technique, which we refer to as reflect and correct, that can learn and predict when the underlying classification system is likely to make mistakes and it suggests acquisitions to correct those mistakes.}},
    author = {Bilgic, Mustafa and Getoor, Lise},
    booktitle = {AAAI},
    priority = {2},
    title = {{Active Inference for Collective Classification}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.169.2441},
    year = {2010}
}
@article{bilgic:TKDD2009,
    author = {Bilgic, Mustafa and Getoor, Lise},
    journal = {ACM Trans. Knowl. Discov. Data},
    month = {December},
    posted-at = {2010-11-27 23:30:11},
    priority = {2},
    publisher = {ACM},
    title = {{Reflect and correct: A misclassification prediction approach to active inference}},
    url = {http://dx.doi.org/10.1145/1631162.1631168},
    volume = {3},
    year = {2009}
}
@inproceedings{bilgic:kdd08,
    author = {Bilgic, Mustafa and Getoor, Lise},
    booktitle = {Proceeding of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining},
    pages = {43--51},
    posted-at = {2010-11-26 13:51:07},
    priority = {2},
    publisher = {ACM},
    series = {KDD '08},
    title = {{Effective label acquisition for collective classification}},
    year = {2008}
}

@article{fadercounting,
 author = {Fader, Peter S. and Hardie, Bruce G. S. and Lee, Ka Lok},
 title = {"Counting Your Customers" the Easy Way: An Alternative to the Pareto/NBD Model},
 journal = {Marketing Science},
 volume = {24},
 number = {2},
 year = {2005},
 pages = {275--284},
 }

@article{schmittleincounting,
 author = {Schmittlein, David C. and Morrison, Donald G. and Colombo, Richard},
 title = {Counting your customers: who are they and what will they do next?},
 journal = {Manage. Sci.},
 volume = {33},
 number = {1},
 year = {1987},
 issn = {0025-1909},
 pages = {1--24},
 }



@inproceedings{melvillelexical,
 author = {Melville, Prem and Gryc, Wojciech and Lawrence, Richard D.},
 title = {Sentiment analysis of blogs by combining lexical knowledge with text classification},
 booktitle = {KDD '09},
 year = {2009},
 }
@InProceedings{attenberg:kdd2011,
  author =       "Josh Attenberg and Foster Provost",
  title =        "Online Active Inference and Learning",
  booktitle =    {KDD},
  year =         "2011",
}
@inproceedings{attprovkdd2010,
    author = {Attenberg, Josh and Provost, Foster},
        booktitle = {KDD},
        title = {{Why label when you can search? Strategies for applying human resources to build classification models under extreme class imbalance}},
            year = {2010}
}
@inproceedings{melvilleADS,
 author = {Melville, Prem and Sindhwani, Vikas},
 title = {Active dual supervision: reducing the cost of annotating examples and features},
 booktitle = {HLT '09},
 year = {2009},
 }

@incollection{weiss10disjunct,
    abstract = {Many classifier induction systems express the induced classifier in terms of a disjunctive description. Small disjuncts are those that classify few training examples. These disjuncts are interesting because they are known to have a much higher error rate than large disjuncts and are responsible for many, if not most, of all classification errors. Previous research has investigated this phenomenon by performing ad hoc analyses of a small number of data sets. In this chapter we provide a much more systematic study of small disjuncts and analyze how they affect classifiers induced from 30 real-world data sets. A new metric, error concentration, is used to show that for these 30 data sets classification errors are often heavily concentrated toward the smaller disjuncts. Various factors, including pruning, training set size, noise, and class imbalance are then analyzed to determine how they affect small disjuncts and the distribution of errors across disjuncts. This analysis provides many insights into why some data sets are difficult to learn from and also provides a better understanding of classifier learning in general.We believe that such an understanding is critical to the development of improved classifier induction algorithms.},
    address = {Boston, MA},
    author = {Weiss, Gary M.},
    booktitle = {Data Mining },
    chapter = {9},
    citeulike-article-id = {6634237},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-1-4419-1280-0_9},
    citeulike-linkout-1 = {http://www.springerlink.com/content/jl51627xk8g79557},
    doi = {10.1007/978-1-4419-1280-0_9},
    editor = {Stahlbock, Robert and Crone, Sven F. and Lessmann, Stefan},
    isbn = {978-1-4419-1279-4},
    pages = {193--226},
    posted-at = {2010-02-05 23:11:00},
    priority = {2},
    publisher = {Springer US},
    title = {The Impact of Small Disjuncts on Classifier Learning},
    url = {http://dx.doi.org/10.1007/978-1-4419-1280-0_9},
    volume = {8},
    year = {2010}
}



@inproceedings{weiss09quant,
    abstract = {In realistic settings the prevalence of a class may change after a classifier is induced and this will degrade the performance of the classifier. Further complicating this scenario is the fact that labeled data is often scarce and expensive. In this paper we address the problem where the class distribution changes and only unlabeled examples are available from the new distribution. We design and evaluate a number of methods for coping with this problem and compare the performance of these methods. Our quantification-based methods estimate the class distribution of the unlabeled data from the changed distribution and adjust the original classifier accordingly, while our semi-supervised methods build a new classifier using the examples from the new (unlabeled) distribution which are supplemented with predicted class values. We also introduce a hybrid method that utilizes both quantification and semi-supervised learning. All methods are evaluated using accuracy and F-measure on a set of benchmark data sets. Our results demonstrate that our methods yield substantial improvements in accuracy and F-measure.},
    address = {New York, NY, USA},
    author = {Xue, Jack C. and Weiss, Gary M.},
    booktitle = {KDD '09: Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining},
    citeulike-article-id = {6557009},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1557117},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1557019.1557117},
    doi = {10.1145/1557019.1557117},
    isbn = {978-1-60558-495-9},
    location = {Paris, France},
    pages = {897--906},
    posted-at = {2010-01-18 16:45:27},
    priority = {2},
    publisher = {ACM},
    title = {Quantification and semi-supervised classification methods for handling changes in class distribution},
    url = {http://dx.doi.org/10.1145/1557019.1557117},
    year = {2009}
}
	
@inproceedings{lomasky2009class,
    abstract = {This paper presents  Active Class Selection  (ACS), a new class of problems for multi-class supervised learning. If one can control the classes from which training data is generated, utilizing feedback during learning to guide the generation of new training data will yield better performance than learning from any  a priori  fixed class distribution. ACS is the process of iteratively selecting class proportions for data generation. In this paper we present several methods for ACS. In an empirical evaluation, we show that for a fixed number of training instances, methods based on increasing class stability outperform methods that seek to maximize class accuracy or that use random sampling. Finally we present results of a deployed system for our motivating application: training an artificial nose to discriminate vapors.},
    address = {Berlin, Heidelberg},
    author = {Lomasky, R. and Brodley, C. E. and Aernecke, M. and Walt, D. and Friedl, M.},
    booktitle = {ECML '07: Proceedings of the 18th European conference on Machine Learning},
    citeulike-article-id = {6463179},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1421731},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/978-3-540-74958-5_63},
    doi = {10.1007/978-3-540-74958-5_63},
    isbn = {978-3-540-74957-8},
    keywords = {active\_class\_selection, active\_learning},
    location = {Warsaw, Poland},
    pages = {640--647},
    posted-at = {2009-12-31 19:06:26},
    priority = {5},
    publisher = {Springer-Verlag},
    title = {Active Class Selection},
    url = {http://dx.doi.org/10.1007/978-3-540-74958-5_63},
    year = {2007}
}

	
@InProceedings{zhu2007imbalance,
  author    = {Zhu, Jingbo  and  Hovy, Eduard},
  title     = {Active Learning for Word Sense Disambiguation with Methods for Addressing the Class Imbalance Problem},
  booktitle = { EMNLP-CoNLL 2007},

  year = {2007},

}



@inproceedings{bloodgood2009imbalance,
    abstract = {Actively sampled data can have very different characteristics than passively sampled data. Therefore, it's promising to investigate using different inference procedures during AL than are used during passive learning (PL). This general idea is explored in detail for the focused case of AL with cost-weighted SVMs for imbalanced data, a situation that arises for many HLT tasks. The key idea behind the proposed InitPA method for addressing imbalance is to base cost models during AL on an estimate of overall corpus imbalance computed via a small unbiased sample rather than the imbalance in the labeled training data, which is the leading method used during PL.},
    author = {Bloodgood, Michael and Shanker, K. Vijay},
    booktitle = {NAACL '09},

    title = {Taking into account the differences between actively and passively acquired data: the case of active learning with support vector machines for imbalanced datasets},
    year = {2009}
}

	

@inproceedings{tomanek2009imbalance,
    abstract = {In lots of natural language processing tasks, the classes to be dealt with often occur heavily imbalanced in the underlying data set and classifiers trained on such skewed data tend to exhibit poor performance for low-frequency classes. We introduce and compare different approaches to reduce class imbalance by design within the context of active learning (AL). Our goal is to compile more balanced data sets up front during annotation time when AL is used as a strategy to acquire training material. We situate our approach in the context of named entity recognition. Our experiments reveal that we can indeed reduce class imbalance and increase the performance of classifiers on minority classes while preserving a good overall performance in terms of macro F-score.},
    author = {Tomanek, Katrin and Hahn, Udo},
    booktitle = {K-CAP '09},

    title = {Reducing class imbalance during active learning for named entity annotation},

    year = {2009}
}

	

@article{baram2004mixing,
    abstract = {This work is concerned with the question of how to combine online an ensemble of active learners so as to expedite the learning progress in pool-based active learning. We develop an active-learning master algorithm, based on a known competitive algorithm for the multiarmed bandit problem. A major challenge in successfully choosing top performing active learners online is to reliably estimate their progress during the learning session. To this end we propose a simple maximum entropy...},
    author = {Baram, Yoram and El-Yaniv, Ran and Luz, Kobi},
    citeulike-article-id = {1730465},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.10.4058},
    journal = {Journal of Machine Learning Research},
    keywords = {active\_learning, bandit},
    pages = {255--291},
    posted-at = {2009-12-14 19:26:12},
    priority = {5},
    title = {Online Choice of Active Learning Algorithms},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.10.4058},
    volume = {5},
    year = {2004}
}

	
@inproceedings{domingos1999metacost,
    abstract = {Research in machine learning, statistics and related fields has produced a wide variety of algorithms for classification. However, most of these algorithms assume that all errors have the same cost, which is seldom the case in KDD prob- lems. Individually making each classification learner costsensitive is laborious, and often non-trivial. In this paper we propose a principled method for making an arbitrary classifier cost-sensitive by wrapping a cost-minimizing procedure around it. This procedure, called MetaCost, treats the underlying classifier as a black box, requiring no knowledge of its functioning or change to it. Unlike stratification, MetaCost is applicable to any number of classes and to arbitrary cost matrices. Empirical trials on a large suite of benchmark databases show that MetaCost almost always produces large cost reductions compared to the cost-blind classifier used (C4.5RULES) and to two forms of stratification. Further tests identify the key components of MetaCost and those that can be varied without substantial loss. Experiments on a larger database indicate that MetaCost scales well.},
    author = {Domingos, Pedro},
    booktitle = {KDD '09},

    title = {MetaCost: A General Method for Making Classifiers Cost-Sensitive},
    year = {1999}
}

	
@article{LiuUndersampling2009,
    abstract = {<para> Undersampling is a popular method in dealing with class-imbalance problems, which uses only a subset of the majority class and thus is very efficient. The main deficiency is that many majority class examples are ignored. We propose two algorithms to overcome this deficiency. <formula formulatype="inline"><tex Notation="TeX">\${tt EasyEnsemble}\$</tex> </formula> samples several subsets from the majority class, trains a learner using each of them, and combines the outputs of those learners. <formula formulatype="inline"><tex Notation="TeX">\${tt BalanceCascade}\$</tex></formula> trains the learners sequentially, where in each step, the majority class examples that are correctly classified by the current trained learners are removed from further consideration. Experimental results show that both methods have higher Area Under the ROC Curve, F-measure, and G-mean values than many existing class-imbalance learning methods. Moreover, they have approximately the same training time as that of undersampling when the same number of weak classifiers is used, which is significantly faster than other methods. </para>},
    author = {Liu, X. Y. and Wu, J. and Zhou, Z. H.},
    booktitle = {Systems, Man, and Cybernetics, Part B: Cybernetics, IEEE Transactions on},
       title = {Exploratory Undersampling for Class-Imbalance Learning},
	  year = {2009}
}

	
@article{chawlaSMOTE2002,
    abstract = {An approach to the construction of classifiers from imbalanced datasets is described. A dataset is imbalanced if the classification categories are not approximately equally represented. Often real-world data sets are predominately composed of \&amp;quot;normal \&amp;quot; examples with only a small percentage of \&amp;quot;abnormal \&amp;quot; or \&amp;quot;interesting \&amp;quot; examples. It is also the case that the cost of misclassifying an abnormal (interesting) example as a normal example is often much higher than the cost of the reverse error. Under-sampling of the majority (normal) class has been proposed as a good means of increasing the sensitivity of a classifier to the minority class. This paper shows that a combination of our method of over-sampling the minority (abnormal) class and under-sampling the majority (normal) class can achieve better classifier performance (in ROC space) than only under-sampling the majority class. This paper also shows that a combination of our method of over-sampling the minority class and under-sampling the majority class can achieve better classifier performance (in ROC space) than varying the loss ratios in Ripper or class priors in Naive Bayes. Our method of over-sampling the minority class involves creating synthetic minority class examples. Experiments are performed using C4.5, Ripper and a Naive Bayes classifier. The method is evaluated using the area under the Receiver Operating Characteristic curve (AUC) and the ROC convex hull strategy. 1.},
    author = {Chawla, Nitesh V. and Bowyer, Kevin W. and Kegelmeyer, Philip W.},
      journal = {J. Artif. Int. Res. },
    pages = {321--357},
    title = {SMOTE: Synthetic Minority Over-sampling Technique},

    volume = {16},
    year = {2002}
}

	

@inproceedings{ErtekinBorder2007,
    abstract = {This paper is concerned with the class imbalance problem which has been known to hinder the learning performance of classification algorithms. The problem occurs when there are significantly less number of observations of the target concept. Various real-world classification tasks, such as medical diagnosis, text categorization and fraud detection suffer from this phenomenon. The standard machine learning algorithms yield better prediction performance with balanced datasets. In this paper, we demonstrate that active learning is capable of solving the class imbalance problem by providing the learner more balanced classes. We also propose an efficient way of selecting informative instances from a smaller pool of samples for active learning which does not necessitate a search through the entire dataset. The proposed method yields an efficient querying system and allows active learning to be applied to very large datasets. Our experimental results show that with an early stopping criteria, active learning achieves a fast solution with competitive prediction performance in imbalanced data classification.},
    address = {New York, NY, USA},
    author = {Ertekin, Seyda and Huang, Jian and Bottou, Leon and Giles, Lee},
    booktitle = {CIKM '07},
      title = {Learning on the border: active learning in imbalanced data classification},

    year = {2007}
}

	

@inproceedings{donmez2008psd,
    author = {Donmez, P. and Carbonell, J.},
    booktitle = {Proc. 10 ths International Symposium on Artificial Intelligence and Mathematics},
    title = {{Paired Sampling in Density-Sensitive Active Learning}},
    year = {2008}
}

	
@inproceedings{zhuDensity2008,

    author = {Zhu, Jingbo and Wang, Huizhen and Yao, Tianshun and Tsou, Benjamin K.},
    booktitle = {COLING '08},
     title = {Active learning with sampling by uncertainty and density for word sense disambiguation and text classification},
    year = {2008}
}

	

@techreport{settles.tr09, Author = {Burr Settles}, Institution = {University of Wisconsin--Madison}, Number = {1648}, Title = {Active Learning Literature Survey}, Type = {Computer Sciences Technical Report}, Year = {2009}
}
@inproceedings{lewis94sequential,
    address = {New York, NY, USA},
    author = {Lewis, David D. and Gale, William A.},
    booktitle = {SIGIR '94: Proceedings of the 17th annual international ACM SIGIR conference on Research and development in information retrieval},
    citeulike-article-id = {1727809},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=188495},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/62437.62470},
    doi = {10.1145/62437.62470},
    isbn = {038719889X},
    keywords = {active\_learning, sequential\_algorithm, text\_classifiers},
    pages = {3--12},
    posted-at = {2009-12-14 16:39:11},
    priority = {2},
    publisher = {Springer-Verlag New York, Inc.},
    title = {A sequential algorithm for training text classifiers},
    url = {http://dx.doi.org/10.1145/62437.62470},
    year = {1994}
}

@inproceedings{ma2009beyond,
    abstract = {Malicious Web sites are a cornerstone of Internet criminal activities. As a result, there has been broad interest in developing systems to prevent the end user from visiting such sites. In this paper, we describe an approach to this problem based on automated URL classification, using statistical methods to discover the tell-tale lexical and host-based properties of malicious Web site URLs. These methods are able to learn highly predictive models by extracting and automatically analyzing tens of thousands of features potentially indicative of suspicious URLs. The resulting classifiers obtain 95-99\% accuracy, detecting large numbers of malicious Web sites from their URLs, with only modest false positives.},
    author = {Ma, Justin and Saul, Lawrence K. and Savage, Stefan and Voelker, Geoffrey M.},
    booktitle = {KDD '09},
    title = {Beyond blacklists: learning to detect malicious web sites from suspicious URLs},
    year = {2009}
}


@inproceedings{lomasky2007class,
    abstract = {This paper presents  Active Class Selection  (ACS), a new class of problems for multi-class supervised learning. If one can control the classes from which training data is generated, utilizing feedback during learning to guide the generation of new training data will yield better performance than learning from any  a priori  fixed class distribution. ACS is the process of iteratively selecting class proportions for data generation. In this paper we present several methods for ACS. In an empirical evaluation, we show that for a fixed number of training instances, methods based on increasing class stability outperform methods that seek to maximize class accuracy or that use random sampling. Finally we present results of a deployed system for our motivating application: training an artificial nose to discriminate vapors.},
    address = {Berlin, Heidelberg},
    author = {Lomasky, R. and Brodley, C. E. and Aernecke, M. and Walt, D. and Friedl, M.},
    booktitle = {ECML '07: Proceedings of the 18th European conference on Machine Learning},
    citeulike-article-id = {6463179},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1421731},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/978-3-540-74958-5_63},
    doi = {10.1007/978-3-540-74958-5_63},
    isbn = {978-3-540-74957-8},
    keywords = {active\_class\_selection, active\_learning},
    location = {Warsaw, Poland},
    pages = {640--647},
    posted-at = {2009-12-31 19:06:26},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {Active Class Selection},
    url = {http://dx.doi.org/10.1007/978-3-540-74958-5_63},
    year = {2007}
}


@misc{fawcett03roc,
    abstract = {Receiver Operating Characteristics (ROC) graphs are a useful technique for organizing classifiers and visualizing their performance. ROC graphs are commonly used in medical decision making, and in recent years have been increasingly adopted in the machine learning and data mining research communities. Although ROC graphs are apparently simple, there are some common misconceptions and pitfalls when using them in practice. This article serves both as a tutorial introduction to ROC graphs and...},
    author = {Fawcett, T.},
    citeulike-article-id = {1113649},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.57.6444},
    posted-at = {2009-12-31 18:47:26},
    priority = {2},
    title = {ROC Graphs: Notes and Practical Considerations for Data Mining Researchers},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.57.6444},
    year = {2003}
}
@article{Saar:2004,
    abstract = {In many cost-sensitive environments class probability estimates are used by decision makers to evaluate the expected utility from a set of alternatives. Supervised learning can be used to build class probability estimates; however, it often is very costly to obtain training data with class labels. Active learning acquires data incrementally, at each phase identifying especially useful additional data for labeling, and can be used to economize on examples needed for learning. We outline the critical features of an active learner and present a sampling-based active learning method for estimating class probabilities and class-based rankings. BOOTSTRAP-LV identifies particularly informative new data for learning based on the variance in probability estimates, and uses weighted sampling to account for a potential example's informative value for the rest of the input space. We show empirically that the method reduces the number of data items that must be obtained and labeled, across a wide variety of domains. We investigate the contribution of the components of the algorithm and show that each provides valuable information to help identify informative examples. We also compare BOOTSTRAP-LV with UNCERTAINTY SAMPLING, an existing active learning method designed to maximize classification accuracy. The results show that BOOTSTRAP-LV uses fewer examples to exhibit a certain estimation accuracy and provide insights to the behavior of the algorithms. Finally, we experiment with another new active sampling algorithm drawing from both UNCERTAINTY SAMPLING and BOOTSTRAP-LV and show that it is significantly more competitive with BOOTSTRAP-LV compared to UNCERTAINTY SAMPLING. The analysis suggests more general implications for improving existing active sampling algorithms for classification.},
    author = {Saar-Tsechansky, Maytal and Provost, Foster},

    journal = {Machine Learning},
    keywords = {active\_learning, critical\_features, probability\_estimation, sampling\_algorithms},
    number = {2},
    pages = {153--178},
    posted-at = {2009-12-19 18:25:34},
    priority = {3},
    publisher = {Springer},
    title = {Active Sampling for Class Probability Estimation and Ranking},
    volume = {54},
    year = {2004}
}
@INPROCEEDINGS{Saar-tsechansky01activelearning,
    author = {Maytal Saar-tsechansky and Foster Provost},
    title = {Active Learning for Class Probability Estimation and Ranking},
    booktitle = {In Proc of the Seventeenth Int Joint Fonf on Artificial Intelligence (IJCAI-2001},
    year = {2001},
    pages = {911--920}
}



@inproceedings{shengKDD2008,
    abstract = {This paper addresses the repeated acquisition of labels for data items when the labeling is imperfect. We examine the improvement (or lack thereof) in data quality via repeated labeling, and focus especially on the improvement of training labels for supervised induction. With the outsourcing of small tasks becoming easier, for example via Rent-A-Coder or Amazon's Mechanical Turk, it often is possible to obtain less-than-expert labeling at low cost. With low-cost labeling, preparing the unlabeled part of the data can become considerably more expensive than labeling. We present repeated-labeling strategies of increasing complexity, and show several main results. (i) Repeated-labeling can improve label quality and model quality, but not always. (ii) When labels are noisy, repeated labeling can be preferable to single labeling even in the traditional setting where labels are not particularly cheap. (iii) As soon as the cost of processing the unlabeled data is not free, even the simple strategy of labeling everything multiple times can give considerable advantage. (iv) Repeatedly labeling a carefully chosen set of points is generally preferable, and we present a robust technique that combines different notions of uncertainty to select data points for which quality should be improved. The bottom line: the results show clearly that when labeling is not perfect, selective acquisition of multiple labels is a strategy that data miners should have in their repertoire; for certain label-quality/cost regimes, the benefit is substantial.},

    author = {Sheng, Victor S. and Provost, Foster and Ipeirotis, Panagiotis G.},
    booktitle = {KDD '08},

    title = {Get another label? improving data quality and data mining using multiple, noisy labelers},

    year = {2008}
}
@ inproceedings{weinbergerICML2009,
    author = {Weinberger, Kilian and Dasgupta, Anirban and Attenberg, Josh and Langford, John and Smola, Alex},
	booktitle={ICML '09},
    title = {Feature Hashing for Large Scale Multitask Learning},
    year = {2009}
}
@article{WeissProvost2003,
    abstract = {For large, real-world inductive learning problems, the number of training examples often must be limited due to the costs associated with procuring, preparing, and storing the training examples and/or the computational costs associated with learning from them. In such circumstances, one question of practical importance is: if only  n  training examples can be selected, in what proportion should the classes be represented? In this article we help to answer this question by analyzing, for a fixed training-set size, the relationship between the class distribution of the training data and the performance of classification trees induced from these data. We study twenty-six data sets and, for each, determine the best class distribution for learning. The naturally occurring class distribution is shown to generally perform well when classifier performance is evaluated using undifferentiated error rate (0/1 loss). However, when the area under the ROC curve is used to evaluate classifier performance, a balanced distribution is shown to perform well. Since neither of these choices for class distribution always generates the best-performing classifier, we introduce a "budget-sensitive" progressive sampling algorithm for selecting training examples based on the class associated with each example. An empirical analysis of this algorithm shows that the class distribution of the resulting training set yields classifiers with good (nearly-optimal) classification performance.},
    author = {Weiss, Gary M. and Provost, Foster},

    journal = {J. Artif. Int. Res.},

    pages = {315--354},

    publisher = {AI Access Foundation},
    title = {Learning when training data are costly: the effect of class distribution on tree induction},
    volume = {19},
    year = {2003}
}


@misc{WeissProvost2001,
    abstract = {In this article we analyze the effect of class distribution on classifier learning. We begin by describing

the different ways in which class distribution affects learning and how it affects the

evaluation of learned classifiers. We then present the results of two comprehensive experimental

studies. The first study compares the performance of classifiers generated from unbalanced data

sets with the performance of classifiers generated from balanced versions of the same data sets.

This...},
    author = {Weiss, G. and Provost, F.},
    citeulike-article-id = {1284148},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.28.9570},
    comment = {this article deals with the influence of class distribution on the performance on classifier performance. The motivating idea here is that biasing the prior distribution during training may be beneficial during testing time, provided that these class probabilities can be corrected (using the same method as elkan 2001). Such biases would include over-sampling the minority class, and training on a uniform distribution. Note that all experiments are performed using C4.5, and therefore are primarily focused on managing the frequentist probability estimates at the regions of parameter space defined by the tree's leaves. The first half of this paper is mainly empirical to test common assumptions.

the first experiment trains and tests on instances drawn from sets with a variety of skews in class distributions. Importantly, in 22/26 sets, most of the errors come from the minority class: true minority instances are misclassified more frequently (26/26), and majority instances are falsely identified as minority more frequently then the vice versa.

the proportion of the minority class in training is varied to find the optimal value. When the goal is to maximize accuracy, the natural distribution seems appropriate, while when maximizing AUC, a more uniform distribution seems more appropriate, sometimes even favoring the minority class. The authors note, however that different training distributions lead to varying performances in different regions of ROC space; a large bias to the minority leads to better performance in the high FP region of the ROC space, and vice versa.

To emphasize the importance of the class distribution in training, the overall training size AND the distribution are varied. it is shown that choosing the best training distribution can offer better test performance than an inappropriate distribution with 2x or 4x the training data. This motivates the need to carefully select class when building a training set.


the proposed selection aglorithm takes n (max \# selections) cmin ( the min proportion of the minority class) and (the geometric factor for step size ). a best ratio is evaluated empriacally by incrementally trained classifiers, and beam search is used to test near-by ratios. successive iterations are sampled on the current best estimated ratio. size is geometrically increasing as a fn of mu, the num chosen by the bottom and top of the beam. },
    keywords = {class\_distribution, class\_selection},
    posted-at = {2009-12-15 17:20:06},
    priority = {0},
    title = {The effect of class distribution on classifier learning},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.28.9570},
    year = {2001}
}


@misc{dmoz,
  howpublished = "\url{http://www.dmoz.org/}"
}
@misc{AMT,
  howpublished = "\url{https://www.mturk.com/mturk/welcome}"
}


@misc{federovOptimal1972 ,
    author = "V. V. Federov",
    year = "1972",
    title = "Theory of optimal experiments",
publisher = {Academic Press},
}


@misc{uci ,
    author = "A. Asuncion and D.J. Newman",
    year = "2007",
    title = "{UCI} Machine Learning Repository",
    url = "http://www.ics.uci.edu/$\sim$mlearn/{MLR}epository.html",
    institution = "University of California, Irvine, School of Information and Computer Sciences" }
@misc{mechanicalturk,
  howpublished = "\url{https://www.mturk.com/}"
}
@article{cohn1992:activeLearning,
    abstract = {Active learning differs from  ” learning from examples” in that the learning algorithm assumes at least some control over what part of the input domain it receives information about. In some situations, active learning is provably more powerful than learning from examples alone, giving better generalization for a fixed number of training examples.

In this article, we consider the problem of learning a binary concept in the absence of noise. We describe a formalism for active concept learning called selective sampling and show how it may be approximately implemented by a neural network. In selective sampling, a learner receives distribution information from the environment and queries an oracle on parts of the domain it considers  ” useful.” We test our implementation, called an SG-network, on three domains and observe significant improvement in generalization.},
    address = {Hingham, MA, USA},
    author = {Cohn, David and Atlas, Les and Ladner, Richard},
    citeulike-article-id = {1727805},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=189489},
    citeulike-linkout-1 = {http://dx.doi.org/10.1023/A:1022673506211},
    doi = {10.1023/A:1022673506211},
    issn = {0885-6125},
    journal = {Mach. Learn.},
    keywords = {active\_learning, ai, pbd},
    month = {May},
    number = {2},
    pages = {201--221},
    posted-at = {2008-05-23 00:20:43},
    priority = {2},
    publisher = {Kluwer Academic Publishers},
    title = {Improving Generalization with Active Learning},
    url = {http://dx.doi.org/10.1023/A:1022673506211},
    volume = {15},
    year = {1994}
}

	
@MISC{Seung92queryby,
    author = {H. S. Seung and M. Opper and H. Sompolinsky},
    title = {Query by Committee},
    year = {1992}
}
@article{tong02svm,
    abstract = {Support vector machines have met with significant success in numerous real-world learning tasks. However, like most machine learning algorithms, they are generally applied using a randomly selected training set classified in advance. In many settings, we also have the option of using \&lt;em\&gt;pool-based active learning\&lt;/em\&gt;. Instead of using a randomly selected training set, the learner has access to a pool of unlabeled instances and can request the labels for some number of them. We introduce a new algorithm for performing active learning with support vector machines, i.e., an algorithm for choosing which instances to request next. We provide a theoretical motivation for the algorithm using the notion of a \&lt;em\&gt;version space\&lt;/em\&gt;. We present experimental results showing that employing our active learning method can significantly reduce the need for labeled training instances in both the standard inductive and transductive settings.},
    address = {Cambridge, MA, USA},
    author = {Tong, Simon and Koller, Daphne},
    citeulike-article-id = {716139},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=944793},
    citeulike-linkout-1 = {http://dx.doi.org/10.1023/A:1009715923555},
    doi = {10.1023/A:1009715923555},
    issn = {1532-4435},
    journal = {J. Mach. Learn. Res.},
    keywords = {active, learning, margin, svm},
    pages = {45--66},
    posted-at = {2009-12-14 15:06:35},
    priority = {2},
    publisher = {JMLR.org},
    title = {Support vector machine active learning with applications to text classification},
    url = {http://dx.doi.org/10.1023/A:1009715923555},
    volume = {2},
    year = {2002}
}
