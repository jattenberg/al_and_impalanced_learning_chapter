\section{Introduction}
\label{sec:intro}

The rich history of predictive modeling has culminated in a diverse set of techniques capable of making accurate predictions on many real-world problems. Many of these techniques demand \emph{training}, whereby a set of instances with ground-truth \emph{labels} (values of a dependent variable) are observed by a model-building process that attempts to capture, at least in part, the relationship between the features of the instances and their labels.  The resultant model can be applied to instances for which the label is not known, to estimate or predict the labels.  These predictions depend not only on the functional structure of the model itself, but on the particular data with which the model was trained.  The accuracy of the predicted labels depends highly on the model's ability to capture an unbiased and sufficient understanding of the characteristics of different classes; in problems where the prevalence of classes is imbalanced, it is necessary to prevent the resultant model from being skewed towards the majority class and to ensure that the model is capable of reflecting the true nature of the minority class.

Another consequence of class imbalance is observed in domains where the ground truth labels in the dataset are not available beforehand and need to be gathered on-demand at some cost.  The costs associated with collecting labels may be due to human labor or as a result of costly incentives, interventions or experiments.  In these settings, simply labeling all available instances may not be practicable, due to budgetary constraints or simply a strong desire to be cost efficient. In a similar fashion to predictive modeling with imbalanced classes, the goal here is to ensure that the budget is not predominantly expended on getting the labels of the majority class instances, and to make sure that the set of instances to be labeled have comparable number of minority class instances as well.

\drop{
In many applications, acquiring a label for a particular instance comes at some cost.  For example, one may employ human labor to ``manually'' examine the instance and record the value of its target variable, often called its label.  In other applications, costly incentives, interventions or experiments may reveal labels.  In such cases, simply labeling all available instances may not be practicable, due to budgetary constraints or simply a strong desire to be cost efficient. The dependence of a model's predictive performance on the selection of data suggests that care should be taken.

The importance of selective label acquisition is evidenced by the vast number of research papers on \emph{active learning}---where the model learned ``so far'' is used in the selection of subsequent data for labeling. This body of research has demonstrated substantial improvements in model generalization performance at a given label budget over a variety of  domains. %However, despite these successes, settings exhibiting strong class imbalance continue to pose a difficult challenge for standard active learning techniques. The intent of this chapter is to provide the reader with some background on these challenges (Section~\ref{sec:background}), detail active learning approaches designed to provide meaningful selections, even when the classes being considered are imbalanced (Sections~\ref{sec:foo} and~\ref{sec:bar}), and to illustrate alternatives to traditional active learning that may be considered when dealing with the most difficult, highly skewed problems.
}
In the context of learning from imbalanced datasets, the role of active learning can be viewed from two different perspectives. The first perspective considers the case where the labels for all the examples in a reasonably large, imbalanced dataset are readily available. The role of active learning in this case is to reduce, and potentially eliminate, any adverse effects that the class imbalance can have on the model's generalization performance. The other perspective addresses the setting where we have prior knowledge that the dataset is imbalanced, and we would like to employ active learning to select  informative examples both from the majority and minority classes for labeling, subject to the constraints of a given budget. The first perspective focuses on active learning's ability to address class imbalance, whereas the second perspective is concerned with the impact of class imbalance on the sampling performance of the active learner. The intent of this chapter is to present a comprehensive analysis of this interplay of active learning and class imbalance. In particular, we first present techniques for dealing \textit{with} the class imbalance problem using active learning and discuss how active learning can alleviate the issues that stem from class imbalance. We show that active learning, even without any adjustments to target class imbalance, is an effective strategy to have a balanced view of the dataset in most cases. It is also possible to further improve the  effectiveness of active learning by tuning its sampling strategy in a class-specific way. Additionally, we will focus on dealing with highly skewed datasets and their impact on the selections performed by an active learning strategy.  Here, we discuss the impact  significant class imbalance has on active learning, and illustrate alternatives to traditional active learning that may be considered when dealing with the most difficult, highly skewed problems.

%%%%%%%
\drop{
Classification is one of the primary tasks of data mining where the goal is to correctly assign uncategorized examples to one or more predefined categories. Being a supervised learning method, a classification task acquires a training dataset to form its model for classifying unseen examples. A training dataset is called imbalanced if at least one of the classes are represented by significantly less number of examples than others. Real world applications often face this problem since normal examples which constitute the majority class in classification problems are generally abundant; on the other hand, the examples of interest are generally rare and form the minority class. Thus, the class imbalance problem is also known as \textit{rarity problem} due to the difficulties in predicting the rare class instances.  Examples of applications which may have class imbalance problem include but are not limited to text categorization \cite{Dumais_1998}, identifying fraudulent credit card transactions \cite{Chan_1998} and telephone calls \cite{Fawcett_1996}, classification of protein databases \cite{Radijovac_2004} and detecting certain objects from satellite images \cite{Kubat_1998}. In addition to the naturally occurring class imbalance problem, imbalanced datasets can also be observed in the commonly used one-against-rest schema in multiclass classification. Therefore, even if the training data is balanced, issues related to the class imbalance problem still can frequently surface. The aforementioned reasons highlight the nature and extent of class imbalance in real-world classification problems, and underscore the need for techniques that address this naturally occurring phenomenon.
}
\drop{
This chapter investigates the utility of Active Learning for addressing the data imbalance problem for classification tasks. We discuss why the principles of Active Learning can significantly alleviate the difficulties that stem from imbalanced class distributions and present empirical analysis that demonstrate the benefits of these principles in practice. We further present a technique to improve both the runtime and generalization performance of training a classifier based on Active Learning. The technique employs an active selection strategy based on ``small pools'', where the search is performed on a much smaller subset of the dataset, offering significant gains in runtime performance for training a classifier. We further propose an early stopping scheme which avoids the unnecessary iterations in Active Learning process and provides the potential to yield higher classification accuracy. Our experimental analysis demonstrates that an Active Learning strategy augmented with these two methods achieves a fast and scalable solution with improved prediction performance. The next part of the chapter demonstrates that Active Learning can even be more useful for imbalanced data classification when combined with an oversampling technique. As opposed to the traditional oversampling techniques that operate as offline preprocessing steps prior to training and either replicate or create synthetic examples by using all the minority class instances, we show that an online oversampling strategy driven by the Active Learner's selection of informative examples can significantly reduce the number of synthetic examples. This prevents the learner from producing unnecessary and redundant synthetic examples that the learner would not make use of, and instead emphasize resampling in the regions where the learner would achieve the most benefit. The experimental analysis presents that such an online resampling scheme based on Active Learning achieves better generalization and runtime performance than either of the two methods used alone.
} 